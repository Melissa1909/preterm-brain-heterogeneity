{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neonatal brain measure estimation from dHCP data\n",
    "As dHCP is under data protection, no data is included in this repository. The code is provided as a reference for the analysis of the dHCP data. To reproduce the analyses, you need to apply for access to the dHCP dataset [here](https://nda.nih.gov/edit_collection.html?id=3955), and parcellate the data with the updated version of the [MCRIBS atlas](https://github.com/DevelopmentalImagingMCRI/MCRIBS). Change the directory `mcribs_data_dir` accordingly. \n",
    "\n",
    "Data can be requested from the authors among reasonable request. I received parcellated data of dHCP release 3 from my collaborators C. Adamson, G. Ball, R. Beare, and J.A.S. de Almeida.\n",
    "\n",
    "This whole notebook should be run for cortical thickness (CT) or surface area (SA). Both measures were used in the original publication. Adjust the variable `brain_measure` to `CT` or `SA` accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import subprocess\n",
    "from functools import reduce\n",
    "from abagen import fetch_desikan_killiany\n",
    "\n",
    "import sys\n",
    "sys.path.append('code')\n",
    "from preprocessing import dhcp_assign_scan_label, dhcp_format_interview_date, dhcp_read_meta, dhcp_strip_id \n",
    "from utils import reorder_vars\n",
    "\n",
    "\n",
    "dhcp_data_dir = 'data/dHCP'\n",
    "mcribs_data_dir = 'data/dHCP/rel3/dhcp-MCRIBS'  # where MCRIBS parcellated data are saved\n",
    "dhcp_data_dir_rel = 'data/dHCP/rel3'  # where the dHCP data are saved\n",
    "\n",
    "dhcp_freesurfer_outputs = join(dhcp_data_dir, 'freesurfer')  # where all freesurfer outputs are stored\n",
    "dhcp_out = join(dhcp_data_dir, 'derivatives')  # where the adapted data will be stored\n",
    "os.makedirs(dhcp_out, exist_ok=True)\n",
    "\n",
    "\n",
    "# adjust brain measurement for which the code should be run\n",
    "brain_measure = 'CT'  # CT or SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MRI related data\n",
    "The dHCP dataset has been published in several releases. Data from release 2 and 3 will be used here. MRI data were parcellated using the MCRIBS atlas, which is a neonatal brain atlas [developed](https://doi.org/10.1038/s41598-020-61326-2) and [updated](https://doi.org/10.1007/s12021-024-09656-8) by Chris Adamson and colleagues. The MCRIBS atlas is available on [GitHub](https://github.com/DevelopmentalImagingMCRI/MCRIBS). The output generated by MCRIBS is similar to FreeSurfer's ?.aparc.annot files and corresponds to the parcellation of the adult Desikan-Killiany atlas. \n",
    "\n",
    "In the updated version of the manuscript, dHCP release 3 with the updated MCRIBS parcellation is used. Therefore, data from release 2 and 3 will be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define aseg columns to be extracted\n",
    "aseg_cols = ['SubCortGrayVol', 'CerebralWhiteMatterVol', 'CortexVol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MRI data\n",
    "### Release 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants in release 2: 542\n"
     ]
    }
   ],
   "source": [
    "# aseg\n",
    "rel2_aseg = pd.read_csv(join(mcribs_data_dir, 'dHCP2_aseg.csv'), index_col=0, sep=',')\n",
    "rel2_aseg.index.name = 'participant'  \n",
    "rel2_aseg = rel2_aseg[aseg_cols] \n",
    "\n",
    "# brain measure\n",
    "if brain_measure == 'CT':\n",
    "    rel2_mri_lh = pd.read_csv(join(mcribs_data_dir, 'dHCP2_lh.dk.ThickAvg.csv'), index_col=0, sep=',')\n",
    "    rel2_mri_rh = pd.read_csv(join(mcribs_data_dir, 'dHCP2_rh.dk.ThickAvg.csv'), index_col=0, sep=',')\n",
    "    rel2_mri = rel2_mri_lh.merge(rel2_mri_rh, on='ThickAvg')\n",
    "elif brain_measure == 'SA':\n",
    "    rel2_mri_lh = pd.read_csv(join(mcribs_data_dir, 'dHCP2_lh.dk.SurfArea.csv'), index_col=0, sep=',')\n",
    "    rel2_mri_rh = pd.read_csv(join(mcribs_data_dir, 'dHCP2_rh.dk.SurfArea.csv'), index_col=0, sep=',')\n",
    "    rel2_mri = rel2_mri_lh.merge(rel2_mri_rh, on='SurfArea')\n",
    "else: \n",
    "    raise ValueError(\"brain_measure must be either 'CT' or 'SA'\")\n",
    "\n",
    "# drop medial wall columns and rename index\n",
    "rel2_mri.drop(columns=['Medial_Wall_x', 'Medial_Wall_y'], inplace=True)  # remove participant column as it is not needed\n",
    "rel2_mri.index.name = 'participant'  \n",
    "\n",
    "# merge brain_measure and aseg data\n",
    "rel2 = rel2_mri.merge(rel2_aseg, on='participant', how='outer')\n",
    "\n",
    "# separate session and participant id\n",
    "rel2 = dhcp_strip_id(rel2)\n",
    "rel2['release'] = 2\n",
    "print(f\"Number of participants in release 2: {len(rel2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants in release 3: 310\n"
     ]
    }
   ],
   "source": [
    "# aseg\n",
    "rel3_aseg = pd.read_csv(join(mcribs_data_dir, 'dHCP3_aseg.csv'), index_col=0, sep=',')\n",
    "rel3_aseg.index.name = 'participant'  \n",
    "rel3_aseg = rel3_aseg[aseg_cols]\n",
    "\n",
    "# brain measure\n",
    "if brain_measure == 'CT':\n",
    "    rel3_mri_lh = pd.read_csv(join(mcribs_data_dir, 'dHCP3_lh.dk.ThickAvg.csv'), index_col=0, sep=',')\n",
    "    rel3_mri_rh = pd.read_csv(join(mcribs_data_dir, 'dHCP3_rh.dk.ThickAvg.csv'), index_col=0, sep=',')\n",
    "    rel3_mri = rel3_mri_lh.merge(rel3_mri_rh, on='ThickAvg')\n",
    "elif brain_measure == 'SA':\n",
    "    rel3_mri_lh = pd.read_csv(join(mcribs_data_dir, 'dHCP3_lh.dk.SurfArea.csv'), index_col=0, sep=',')\n",
    "    rel3_mri_rh = pd.read_csv(join(mcribs_data_dir, 'dHCP3_rh.dk.SurfArea.csv'), index_col=0, sep=',')\n",
    "    rel3_mri = rel3_mri_lh.merge(rel3_mri_rh, on='SurfArea')\n",
    "else: \n",
    "    raise ValueError(\"brain_measure must be either 'CT' or 'SA'\")\n",
    "\n",
    "# drop medial wall columns and rename index\n",
    "rel3_mri.drop(columns=['Medial_Wall_x', 'Medial_Wall_y'], inplace=True)  # remove participant column as it is not needed\n",
    "rel3_mri.index.name = 'participant'  \n",
    "\n",
    "# merge brain_measure and aseg data\n",
    "rel3 = rel3_mri.merge(rel3_aseg, on='participant', how='outer')\n",
    "\n",
    "# separate session and participant id\n",
    "rel3 = dhcp_strip_id(rel3)\n",
    "rel3['release'] = 3\n",
    "print(f\"Number of participants in release 3: {len(rel3.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dHCP data shape: (852, 74)\n",
      "Number of IDPs in DKT atlas: 68\n"
     ]
    }
   ],
   "source": [
    "# combine data from release 2 and 3\n",
    "dhcp_mri = pd.concat([rel2, rel3], axis=0)\n",
    "dhcp_mri.sort_values(by=['Subject_ID', 'Session_ID'], inplace=True)\n",
    "print(f\"Combined dHCP data shape: {dhcp_mri.shape}\")\n",
    "\n",
    "\n",
    "# get region names of the Desikan-Killiany atlas as now used in the dHCP data\n",
    "dhcp_idps_idx_wo_nan = dhcp_mri.filter(regex=f'ctx-').columns\n",
    "print(f\"Number of IDPs in DKT atlas: {len(dhcp_idps_idx_wo_nan)}\")\n",
    "\n",
    "# mean CT\n",
    "if brain_measure == 'CT':\n",
    "    dhcp_mri['meanCT2'] = dhcp_mri[dhcp_idps_idx_wo_nan].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Match DKT to DK atlas\n",
    "Some regions are missing in the DKT atlas that are present in the DK atlas (bankssts, frontalpole, temporalpole). -->\n",
    "\n",
    "## Load DK atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access DK atlas and save idp_labels\n",
    "atlas = fetch_desikan_killiany(surface=True)\n",
    "atlas = pd.read_csv(atlas['info'])\n",
    "atlas = atlas[(atlas['structure'] == 'cortex') & (atlas['hemisphere'] == 'L')]\n",
    "atlas_labels_l = ['L_'+label for label in atlas['label']]\n",
    "atlas_labels_r = ['R_'+label for label in atlas['label']]\n",
    "\n",
    "desikan_idps = atlas_labels_l + atlas_labels_r  # save correct labels to rename the columns later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns of dhcp_mri\n",
    "dk_labels_raw = atlas['label'].tolist()\n",
    "dk_labels_dhcp = [f'ctx-{hemisphere}-{label}' for hemisphere in ['lh', 'rh'] for label in dk_labels_raw]\n",
    "dhcp_mri = reorder_vars(['Subject_ID', 'Session_ID', 'release'], dhcp_mri, dk_labels_dhcp)\n",
    "\n",
    "# sorting dhcp_idps_idx\n",
    "dhcp_idps_idx = dhcp_mri.filter(regex=f'ctx-').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load meta information\n",
    "meta = dhcp_read_meta(join(dhcp_data_dir_rel, 'nnsi01.txt'))\n",
    "meta = meta[['src_subject_id', 'interview_date', 'sex', 'nscan_ga_at_birth_weeks', 'nscan_ga_at_scan_weeks', \n",
    "            'radiology_score', 'scan_validation']]\n",
    "meta['scan_validation'] = ['ses-' + str(ses) for ses in meta['scan_validation']] \n",
    "\n",
    "# rename columns and adjust data types\n",
    "meta.rename(columns={'src_subject_id': 'Subject_ID', \n",
    "                    'scan_validation': 'Session_ID',\n",
    "                    'nscan_ga_at_birth_weeks': 'gestational_age', \n",
    "                    'nscan_ga_at_scan_weeks': 'scan_age'}, inplace=True)\n",
    "\n",
    "meta['scan_age'] = meta['scan_age'].astype(float)\n",
    "meta['gestational_age'] = meta['gestational_age'].astype(float)\n",
    "\n",
    "# format interview date to be consistent across subjects\n",
    "meta['interview_date_formatted'] = meta['interview_date'].apply(dhcp_format_interview_date)\n",
    "meta.drop(columns=['interview_date'], inplace=True)\n",
    "\n",
    "# assign session and scan labels\n",
    "meta['session_num'] = meta.groupby('Subject_ID').cumcount() + 1\n",
    "meta['scan'] = meta.apply(dhcp_assign_scan_label, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge meta with MRI data  \n",
    "Although some subjects have multiple scans (i.e., term-equivalent and fetal), we will only keep the term-equivalent scan for each subject. This is because the normative model will be trained on term-born subjects only, for whom only term-equivalent scans are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhcp = dhcp_mri.merge(meta, on=['Subject_ID', 'Session_ID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dHCP data shape: (701, 82)\n",
      "Final dHCP data shape after keeping only last term-equivalent scan: (695, 82)\n"
     ]
    }
   ],
   "source": [
    "# only keep term-equivalent scans\n",
    "dhcp = dhcp[dhcp['scan'] == 'term_equivalent']\n",
    "print(f\"Final dHCP data shape: {dhcp.shape}\")\n",
    "\n",
    "# if subject has multiple scans at term-equivalent age, keep the last one\n",
    "termeq_df = dhcp[dhcp['scan'] == 'term_equivalent']\n",
    "termeq_df = termeq_df.sort_values(by=['Subject_ID', 'Session_ID']).groupby('Subject_ID').last().reset_index()\n",
    "\n",
    "fetal_df = dhcp[dhcp['scan'] == 'fetal']\n",
    "dhcp = pd.concat([termeq_df, fetal_df], ignore_index=True)\n",
    "\n",
    "print(f\"Final dHCP data shape after keeping only last term-equivalent scan: {dhcp.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data about cognition and birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhcp_tab_data = {\n",
    "    join(dhcp_data_dir_rel, 'bsid_iii01.txt'):  ['bsid_cog_composite'], \n",
    "    # join(dhcp_data_dir_rel, 'cpenr01.txt'):     ['mother_education1', 'mother_occupation', 'father_education1', 'father_occupation'], \n",
    "    join(dhcp_data_dir_rel, 'lpb01.txt'):       ['baby_birth_weight'], \n",
    "}\n",
    "\n",
    "# read data\n",
    "dhcp_tab = []\n",
    "for k in dhcp_tab_data.keys():\n",
    "    tab = pd.read_csv(k, header=0, skiprows=[1], delimiter=\"\\t\", na_values=['-998', '-999', ''], \n",
    "                        low_memory=False)\n",
    "    tab = tab[[\"src_subject_id\"] + dhcp_tab_data[k]]     \n",
    "    dhcp_tab.append(tab)\n",
    "    \n",
    "# combine data\n",
    "dhcp_tab = reduce(lambda left, right: pd.merge(left, right, on=[\"src_subject_id\"], how='left'), dhcp_tab)\n",
    "\n",
    "# rename columns\n",
    "dhcp_tab.rename(columns={'src_subject_id': 'Subject_ID',\n",
    "                        'baby_birth_weight': 'BW'}, inplace=True)\n",
    "\n",
    "# transform BW into grams\n",
    "dhcp_tab['BW'] = dhcp_tab['BW'] * 1000  # convert kg to grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust and rename variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge \n",
    "dhcp = dhcp.merge(dhcp_tab, on=['Subject_ID'], how='left') \n",
    "\n",
    "\n",
    "# rename variables\n",
    "dhcp = dhcp.rename(columns=dict(\n",
    "    SubCortGrayVol=\"sGMV\",\n",
    "    CerebralWhiteMatterVol=\"WMV\",\n",
    "    CortexVol=\"GMV\"\n",
    "))  \n",
    "\n",
    "# reorder variables to match the Desikan-Killiany atlas\n",
    "dhcp = dhcp.rename(columns=dict(zip(dhcp_idps_idx, desikan_idps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preterm variable\n",
    "dhcp['dx'] = np.where(dhcp['gestational_age'] < 37, 'preterm', 'CN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [r[2:] for r in desikan_idps[:34]]\n",
    "\n",
    "# Combine L_ and R_ values\n",
    "for region in regions:\n",
    "    dhcp[f'{brain_measure}_{region}'] = dhcp[[f'L_{region}', f'R_{region}']].mean(axis=1)\n",
    "    # drop L_ and R_ columns\n",
    "    dhcp = dhcp.drop(columns=[f'L_{region}', f'R_{region}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create region list bilateral\n",
    "desikan_idps_bilateral = [f'{brain_measure}_{region}' for region in regions]\n",
    "ctv_columns = ['GMV', 'WMV', 'sGMV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapt df for BrainChart framework\n",
    "BrainChart needs a certain format of the data. We will adapt the data accordingly. More information can be found [here](https://brainchart.shinyapps.io/brainchart/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data shape: (695, 59)\n"
     ]
    }
   ],
   "source": [
    "# adapt for brainchart\n",
    "dhcp = dhcp.rename(columns=dict(\n",
    "    Subject_ID=\"participant\",\n",
    "    gestational_age=\"GA\",\n",
    "    baby_birth_weight=\"BW\",\n",
    ")) \n",
    "\n",
    "# sex\n",
    "dhcp['sex'] = dhcp['sex'].replace({'F': 'Female', 'M': 'Male'})\n",
    "\n",
    "# age\n",
    "dhcp['age_days'] = dhcp['scan_age'] * 7  # because scan_age is in weeks\n",
    "dhcp['Age'] = (dhcp['age_days']-280) / 365.245  # from BrainChart instructions\n",
    "\n",
    "# other required info\n",
    "dhcp['study'] = 'dHCP_NewEstimation'  # as dHCP was used for original model fitting, we want to make sure that random effects of study are calculated again\n",
    "#dhcp['study'] = [f'dHCP_{i}' for i in dhcp['scan']]\n",
    "\n",
    "dhcp['fs_version'] = 'Custom' \n",
    "dhcp['country'] = 'Multisite'\n",
    "dhcp['run'] = 1\n",
    "dhcp['session'] = 1\n",
    "\n",
    "# reshape\n",
    "all_idps = desikan_idps_bilateral + ctv_columns\n",
    "dhcp_final = reorder_vars(['participant', 'Age', 'age_days', 'sex', 'study', 'fs_version','country', 'run', \n",
    "                            'session', 'dx'], dhcp, all_idps)\n",
    "\n",
    "# save\n",
    "print('Final data shape:', dhcp_final.shape)\n",
    "dhcp_final.to_csv(os.path.join(dhcp_out, f'dHCP_{brain_measure}_preprocessed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats\n",
    "Summary stats shown in Supp Table S1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- STATS FOR term_equivalent SCANS ----\n",
      "Data available for 564 term subjects and 131 preterm subjects\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">CN</th>\n",
       "      <th colspan=\"5\" halign=\"left\">preterm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">term_equivalent</th>\n",
       "      <th colspan=\"5\" halign=\"left\">term_equivalent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Age [weeks]</th>\n",
       "      <th>BW [g]</th>\n",
       "      <th>Bayley]</th>\n",
       "      <th>GA [weeks]</th>\n",
       "      <th>Male [%]</th>\n",
       "      <th>Age [weeks]</th>\n",
       "      <th>BW [g]</th>\n",
       "      <th>Bayley</th>\n",
       "      <th>GA [weeks]</th>\n",
       "      <th>Male [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>564.00</td>\n",
       "      <td>451.00</td>\n",
       "      <td>452.00</td>\n",
       "      <td>564.00</td>\n",
       "      <td>564.00</td>\n",
       "      <td>131.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>131.00</td>\n",
       "      <td>131.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.40</td>\n",
       "      <td>3394.01</td>\n",
       "      <td>101.05</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.87</td>\n",
       "      <td>1714.27</td>\n",
       "      <td>98.91</td>\n",
       "      <td>31.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>1.72</td>\n",
       "      <td>494.57</td>\n",
       "      <td>10.92</td>\n",
       "      <td>1.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.09</td>\n",
       "      <td>720.23</td>\n",
       "      <td>12.78</td>\n",
       "      <td>3.84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>41.43</td>\n",
       "      <td>3420.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>40.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.86</td>\n",
       "      <td>1640.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>32.14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.43</td>\n",
       "      <td>1820.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>23.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.86</td>\n",
       "      <td>4750.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.14</td>\n",
       "      <td>3280.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>36.86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    CN                                              preterm  \\\n",
       "       term_equivalent                                      term_equivalent   \n",
       "           Age [weeks]   BW [g] Bayley] GA [weeks] Male [%]     Age [weeks]   \n",
       "n               564.00   451.00  452.00     564.00   564.00          131.00   \n",
       "mean             41.40  3394.01  101.05      40.00      NaN           40.87   \n",
       "%                  NaN      NaN     NaN        NaN    53.19             NaN   \n",
       "sd                1.72   494.57   10.92       1.27      NaN            2.09   \n",
       "median           41.43  3420.00  100.00      40.14      NaN           40.86   \n",
       "min              37.43  1820.00   55.00      37.00      NaN           37.00   \n",
       "max              44.86  4750.00  125.00      43.00      NaN           45.14   \n",
       "\n",
       "                                             \n",
       "                                             \n",
       "         BW [g]  Bayley GA [weeks] Male [%]  \n",
       "n        101.00  101.00     131.00   131.00  \n",
       "mean    1714.27   98.91      31.78      NaN  \n",
       "%           NaN     NaN        NaN    54.96  \n",
       "sd       720.23   12.78       3.84      NaN  \n",
       "median  1640.00  100.00      32.14      NaN  \n",
       "min      540.00   55.00      23.57      NaN  \n",
       "max     3280.00  125.00      36.86      NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhcp_final['age_weeks'] = dhcp_final['age_days'] / 7\n",
    "\n",
    "dhcp_final_pt = dhcp_final[dhcp_final['dx'] == 'preterm']\n",
    "dhcp_final_cn = dhcp_final[dhcp_final['dx'] == 'CN']\n",
    "\n",
    "# summary statistics\n",
    "dhcp_sample_stats = dict()\n",
    "for tp in [\"term_equivalent\"]:\n",
    "    print(f\"---- STATS FOR {tp} SCANS ----\")\n",
    "    cn = dhcp_final.loc[(dhcp_final.scan==tp) & (dhcp_final.dx=='CN')]\n",
    "    pt = dhcp_final.loc[(dhcp_final.scan==tp) & (dhcp_final.dx=='preterm')]\n",
    "\n",
    "    print(f\"Data available for {len(cn)} term subjects and {len(pt)} preterm subjects\")\n",
    "\n",
    "    # age\n",
    "    dhcp_sample_stats[(\"CN\", tp, \"Age [weeks]\")] = cn['age_weeks'].describe()\n",
    "    dhcp_sample_stats[(\"preterm\", tp, \"Age [weeks]\")] = pt['age_weeks'].describe()\n",
    "    \n",
    "    # sex\n",
    "    dhcp_sample_stats[(\"CN\", tp, \"Male [%]\")] = pd.Series({\n",
    "        \"count\": len(cn.sex),\n",
    "        \"%\": (cn['sex'] == \"Male\").sum() / len(cn.sex) * 100\n",
    "    })\n",
    "    \n",
    "    dhcp_sample_stats[(\"preterm\", tp, \"Male [%]\")] = pd.Series({\n",
    "        \"count\": len(pt.sex),\n",
    "        \"%\": (pt['sex'] == \"Male\").sum() / len(pt.sex) * 100 \n",
    "    })\n",
    "    \n",
    "    # GA\n",
    "    dhcp_sample_stats[(\"CN\", tp, \"GA [weeks]\")] = cn['GA'].describe()\n",
    "    dhcp_sample_stats[(\"preterm\", tp, \"GA [weeks]\")] = pt['GA'].describe()\n",
    "    \n",
    "    # BW\n",
    "    dhcp_sample_stats[(\"CN\", tp, \"BW [g]\")] = cn['BW'].describe()\n",
    "    dhcp_sample_stats[(\"preterm\", tp, \"BW [g]\")] = pt['BW'].describe()\n",
    "    \n",
    "    # cognition\n",
    "    dhcp_sample_stats[(\"CN\", tp, \"Bayley]\")] = cn['bsid_cog_composite'].describe()\n",
    "    dhcp_sample_stats[(\"preterm\", tp, \"Bayley\")] = pt['bsid_cog_composite'].describe()\n",
    "    \n",
    "\n",
    "dhcp_sample_stats = pd.DataFrame(dhcp_sample_stats).sort_index(axis=1)\n",
    "dhcp_sample_stats = dhcp_sample_stats.loc[[\"count\", \"mean\", \"%\", \"std\", \"50%\", \"min\", \"max\"],:]\n",
    "dhcp_sample_stats = dhcp_sample_stats.rename(index={\"count\":\"n\", \"50%\":\"median\", \"std\":\"sd\"})\n",
    "dhcp_sample_stats = dhcp_sample_stats.round(2)\n",
    "dhcp_sample_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared test for sex difference between groups: Chi=0.072, p-value: 0.788\n",
      "t-test for Age at scan: t=-3.036, p-value: 0.002\n",
      "t-test for Bayley scores: t=-1.724, p-value: 0.085\n",
      "t-test for GA scores: t=-42.063, p-value: 5.85e-193\n",
      "t-test for BW scores: t=-28.121, p-value: 1.67e-108\n"
     ]
    }
   ],
   "source": [
    "# test significance\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "contingency_table = pd.crosstab(dhcp_final['dx'], dhcp_final['sex'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-squared test for sex difference between groups: Chi={chi2:.3f}, p-value: {p:.3f}\")\n",
    "\n",
    "t, p = ttest_ind(dhcp_final_pt['Age'], dhcp_final_cn['Age'], nan_policy='omit', equal_var=True)\n",
    "print(f\"t-test for Age at scan: t={t:.3f}, p-value: {p:.3f}\")\n",
    "\n",
    "t, p = ttest_ind(dhcp_final_pt['bsid_cog_composite'], dhcp_final_cn['bsid_cog_composite'], nan_policy='omit', equal_var=True)\n",
    "print(f\"t-test for Bayley scores: t={t:.3f}, p-value: {p:.3f}\")\n",
    "\n",
    "t, p = ttest_ind(dhcp_final_pt['GA'], dhcp_final_cn['GA'], nan_policy='omit', equal_var=True)\n",
    "print(f\"t-test for GA scores: t={t:.3f}, p-value: {p:.2e}\")\n",
    "\n",
    "t, p = ttest_ind(dhcp_final_pt['BW'], dhcp_final_cn['BW'], nan_policy='omit', equal_var=True)\n",
    "print(f\"t-test for BW scores: t={t:.3f}, p-value: {p:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
